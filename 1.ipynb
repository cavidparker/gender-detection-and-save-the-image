{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import load_model\n",
    "from keras.utils import get_file\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import os\n",
    "import cvlib as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwnld_link = \"https://github.com/arunponnusamy/cvlib/releases/download/v0.2.0/gender_detection.model\"\n",
    "model_path = get_file(\"gender_detection.model\", dwnld_link,\n",
    "                     cache_subdir=\"pre-trained\", cache_dir=os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "webcam = cv2.VideoCapture(0)\n",
    "\n",
    "if not webcam.isOpened():\n",
    "    print(\"Could not open webcam\")\n",
    "    exit()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['man','woman']\n",
    "counter = 0\n",
    "counter1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[292, 207, 443, 413]]\n",
      "[0.99814093]\n",
      "[[292, 207, 443, 413]]\n",
      "[0.99814093]\n",
      "[[288, 204, 439, 413]]\n",
      "[0.99539423]\n",
      "[[288, 204, 439, 413]]\n",
      "[0.99539423]\n",
      "[[285, 204, 438, 414]]\n",
      "[0.99151456]\n",
      "[[285, 204, 438, 414]]\n",
      "[0.99151456]\n",
      "[[287, 204, 439, 413]]\n",
      "[0.99442416]\n",
      "[[287, 204, 439, 413]]\n",
      "[0.99442416]\n",
      "[[288, 202, 437, 413]]\n",
      "[0.9968285]\n",
      "[[288, 202, 437, 413]]\n",
      "[0.9968285]\n",
      "[[289, 203, 437, 411]]\n",
      "[0.99764675]\n",
      "[[289, 203, 437, 411]]\n",
      "[0.99764675]\n",
      "[[287, 203, 436, 412]]\n",
      "[0.9950582]\n",
      "[[287, 203, 436, 412]]\n",
      "[0.9950582]\n",
      "[[287, 201, 434, 412]]\n",
      "[0.9942391]\n",
      "[[287, 201, 434, 412]]\n",
      "[0.9942391]\n",
      "[[286, 201, 433, 411]]\n",
      "[0.9940162]\n",
      "[[286, 201, 433, 411]]\n",
      "[0.9940162]\n",
      "[[284, 201, 432, 410]]\n",
      "[0.99341464]\n",
      "[[284, 201, 432, 410]]\n",
      "[0.99341464]\n",
      "[[282, 200, 431, 411]]\n",
      "[0.98733085]\n",
      "[[282, 200, 431, 411]]\n",
      "[0.98733085]\n",
      "[[277, 206, 431, 413]]\n",
      "[0.9634176]\n",
      "[[277, 206, 431, 413]]\n",
      "[0.9634176]\n",
      "[[274, 205, 428, 412]]\n",
      "[0.91241974]\n",
      "[[274, 205, 428, 412]]\n",
      "[0.91241974]\n",
      "[[272, 215, 425, 413]]\n",
      "[0.93881345]\n",
      "[[272, 215, 425, 413]]\n",
      "[0.93881345]\n",
      "[[269, 215, 425, 414]]\n",
      "[0.9128119]\n",
      "[[269, 215, 425, 414]]\n",
      "[0.9128119]\n",
      "[[270, 215, 425, 416]]\n",
      "[0.8956799]\n",
      "[[270, 215, 425, 416]]\n",
      "[0.8956799]\n",
      "[[273, 202, 426, 414]]\n",
      "[0.8749726]\n",
      "[[273, 202, 426, 414]]\n",
      "[0.8749726]\n",
      "[[269, 211, 425, 413]]\n",
      "[0.94070786]\n",
      "[[269, 211, 425, 413]]\n",
      "[0.94070786]\n",
      "[[273, 191, 424, 412]]\n",
      "[0.9356064]\n",
      "[[273, 191, 424, 412]]\n",
      "[0.9356064]\n",
      "[[273, 194, 423, 409]]\n",
      "[0.9473484]\n",
      "[[273, 194, 423, 409]]\n",
      "[0.9473484]\n",
      "[[273, 208, 424, 409]]\n",
      "[0.96862304]\n",
      "[[273, 208, 424, 409]]\n",
      "[0.96862304]\n",
      "[[273, 193, 423, 406]]\n",
      "[0.96307236]\n",
      "[[273, 193, 423, 406]]\n",
      "[0.96307236]\n",
      "[[273, 193, 424, 408]]\n",
      "[0.9676513]\n",
      "[[273, 193, 424, 408]]\n",
      "[0.9676513]\n",
      "[[272, 194, 424, 408]]\n",
      "[0.9667063]\n",
      "[[272, 194, 424, 408]]\n",
      "[0.9667063]\n",
      "[[274, 195, 424, 406]]\n",
      "[0.97010744]\n",
      "[[274, 195, 424, 406]]\n",
      "[0.97010744]\n",
      "[[274, 195, 423, 407]]\n",
      "[0.9571396]\n",
      "[[274, 195, 423, 407]]\n",
      "[0.9571396]\n",
      "[[274, 194, 424, 408]]\n",
      "[0.96900415]\n",
      "[[274, 194, 424, 408]]\n",
      "[0.96900415]\n",
      "[[274, 192, 424, 408]]\n",
      "[0.97404885]\n",
      "[[274, 192, 424, 408]]\n",
      "[0.97404885]\n",
      "[[274, 195, 424, 407]]\n",
      "[0.96811837]\n",
      "[[274, 195, 424, 407]]\n",
      "[0.96811837]\n",
      "[[275, 197, 426, 408]]\n",
      "[0.97530544]\n",
      "[[275, 197, 426, 408]]\n",
      "[0.97530544]\n",
      "[[275, 198, 426, 411]]\n",
      "[0.9635593]\n",
      "[[275, 198, 426, 411]]\n",
      "[0.9635593]\n",
      "[[276, 211, 427, 409]]\n",
      "[0.96867305]\n",
      "[[276, 211, 427, 409]]\n",
      "[0.96867305]\n",
      "[[273, 210, 427, 408]]\n",
      "[0.967557]\n",
      "[[273, 210, 427, 408]]\n",
      "[0.967557]\n",
      "[[274, 209, 426, 409]]\n",
      "[0.9658244]\n",
      "[[274, 209, 426, 409]]\n",
      "[0.9658244]\n",
      "[[275, 213, 426, 412]]\n",
      "[0.96030116]\n",
      "[[275, 213, 426, 412]]\n",
      "[0.96030116]\n",
      "[[275, 215, 426, 411]]\n",
      "[0.95467967]\n",
      "[[275, 215, 426, 411]]\n",
      "[0.95467967]\n",
      "[[275, 214, 426, 411]]\n",
      "[0.96092874]\n",
      "[[275, 214, 426, 411]]\n",
      "[0.96092874]\n",
      "[[276, 198, 424, 411]]\n",
      "[0.95387816]\n",
      "[[276, 198, 424, 411]]\n",
      "[0.95387816]\n",
      "[[275, 209, 425, 412]]\n",
      "[0.9579807]\n",
      "[[275, 209, 425, 412]]\n",
      "[0.9579807]\n",
      "[[273, 210, 424, 410]]\n",
      "[0.95551646]\n",
      "[[273, 210, 424, 410]]\n",
      "[0.95551646]\n",
      "[[272, 211, 424, 412]]\n",
      "[0.96077764]\n",
      "[[272, 211, 424, 412]]\n",
      "[0.96077764]\n",
      "[[270, 210, 425, 413]]\n",
      "[0.9360821]\n",
      "[[270, 210, 425, 413]]\n",
      "[0.9360821]\n",
      "[[268, 210, 424, 410]]\n",
      "[0.9372118]\n",
      "[[268, 210, 424, 410]]\n",
      "[0.9372118]\n",
      "[[267, 209, 424, 411]]\n",
      "[0.9247301]\n",
      "[[267, 209, 424, 411]]\n",
      "[0.9247301]\n",
      "[[269, 210, 424, 412]]\n",
      "[0.9165727]\n",
      "[[269, 210, 424, 412]]\n",
      "[0.9165727]\n",
      "[[267, 209, 422, 412]]\n",
      "[0.9183761]\n",
      "[[267, 209, 422, 412]]\n",
      "[0.9183761]\n",
      "[[267, 208, 421, 409]]\n",
      "[0.91704464]\n",
      "[[267, 208, 421, 409]]\n",
      "[0.91704464]\n",
      "[[268, 208, 420, 409]]\n",
      "[0.91053325]\n",
      "[[268, 208, 420, 409]]\n",
      "[0.91053325]\n",
      "[[266, 210, 419, 410]]\n",
      "[0.8773933]\n",
      "[[266, 210, 419, 410]]\n",
      "[0.8773933]\n",
      "[[265, 208, 420, 409]]\n",
      "[0.87850237]\n",
      "[[265, 208, 420, 409]]\n",
      "[0.87850237]\n",
      "[[269, 188, 420, 412]]\n",
      "[0.8579348]\n",
      "[[269, 188, 420, 412]]\n",
      "[0.8579348]\n",
      "[[265, 208, 421, 409]]\n",
      "[0.9006044]\n",
      "[[265, 208, 421, 409]]\n",
      "[0.9006044]\n",
      "[[265, 209, 420, 411]]\n",
      "[0.8843832]\n",
      "[[265, 209, 420, 411]]\n",
      "[0.8843832]\n",
      "[[265, 210, 420, 409]]\n",
      "[0.8975896]\n",
      "[[265, 210, 420, 409]]\n",
      "[0.8975896]\n",
      "[[267, 208, 420, 409]]\n",
      "[0.88321954]\n",
      "[[267, 208, 420, 409]]\n",
      "[0.88321954]\n",
      "[[266, 209, 421, 408]]\n",
      "[0.9105798]\n",
      "[[266, 209, 421, 408]]\n",
      "[0.9105798]\n",
      "[[265, 210, 420, 409]]\n",
      "[0.9052578]\n",
      "[[265, 210, 420, 409]]\n",
      "[0.9052578]\n",
      "[[269, 188, 420, 412]]\n",
      "[0.8777201]\n",
      "[[269, 188, 420, 412]]\n",
      "[0.8777201]\n",
      "[[269, 188, 420, 411]]\n",
      "[0.9011924]\n",
      "[[269, 188, 420, 411]]\n",
      "[0.9011924]\n",
      "[[268, 187, 419, 411]]\n",
      "[0.8698968]\n",
      "[[268, 187, 419, 411]]\n",
      "[0.8698968]\n",
      "[[264, 211, 414, 410]]\n",
      "[0.86835295]\n",
      "[[264, 211, 414, 410]]\n",
      "[0.86835295]\n",
      "[[261, 184, 413, 409]]\n",
      "[0.95350456]\n",
      "[[261, 184, 413, 409]]\n",
      "[0.95350456]\n",
      "[[262, 183, 412, 407]]\n",
      "[0.94655406]\n",
      "[[262, 183, 412, 407]]\n",
      "[0.94655406]\n",
      "[[259, 206, 410, 403]]\n",
      "[0.9578193]\n",
      "[[259, 206, 410, 403]]\n",
      "[0.9578193]\n",
      "[[261, 208, 410, 402]]\n",
      "[0.97108984]\n",
      "[[261, 208, 410, 402]]\n",
      "[0.97108984]\n",
      "[[262, 209, 410, 404]]\n",
      "[0.9693291]\n",
      "[[262, 209, 410, 404]]\n",
      "[0.9693291]\n",
      "[[260, 209, 411, 408]]\n",
      "[0.9520253]\n",
      "[[260, 209, 411, 408]]\n",
      "[0.9520253]\n"
     ]
    }
   ],
   "source": [
    "while webcam.isOpened():\n",
    "\n",
    "    # read frame from webcam \n",
    "    status, frame = webcam.read()\n",
    "\n",
    "    if not status:\n",
    "        print(\"Could not read frame\")\n",
    "        exit()\n",
    "\n",
    "    # apply face detection\n",
    "    face, confidence = cv.detect_face(frame)\n",
    "\n",
    "    print(face)\n",
    "    print(confidence)\n",
    "    face, confidence = cv.detect_face(frame)\n",
    "\n",
    "    print(face)\n",
    "    print(confidence)\n",
    "\n",
    "    # loop through detected faces\n",
    "    for idx, f in enumerate(face):\n",
    "\n",
    "        # get corner points of face rectangle        \n",
    "        (startX, startY) = f[0], f[1]\n",
    "        (endX, endY) = f[2], f[3]\n",
    "\n",
    "        # draw rectangle over face\n",
    "        cv2.rectangle(frame, (startX,startY), (endX,endY), (0,255,0), 2)\n",
    "        if (classes == 'man'):\n",
    "            cv2.imwrite(\"G:/Devnet/gender-detection-keras/man/\" + \"man\"+str(counter)+\".png\",frame)\n",
    "            counter = counter + 1\n",
    "\n",
    "        # crop the detected face region\n",
    "        face_crop = np.copy(frame[startY:endY,startX:endX])\n",
    "\n",
    "        if (face_crop.shape[0]) < 10 or (face_crop.shape[1]) < 10:\n",
    "            continue\n",
    "\n",
    "        # preprocessing for gender detection model\n",
    "        face_crop = cv2.resize(face_crop, (96,96))\n",
    "        face_crop = face_crop.astype(\"float\") / 255.0\n",
    "        face_crop = img_to_array(face_crop)\n",
    "        face_crop = np.expand_dims(face_crop, axis=0)\n",
    "#         if (classes == 'man'):\n",
    "#             cv2.imwrite(\"G:/Devnet/gender-detection-keras/man/\" + \"man\"+str(counter)+\".png\",face_crop)\n",
    "#             counter = counter + 1\n",
    "\n",
    "#         # apply gender detection on face\n",
    "#         conf = model.predict(face_crop)[0]\n",
    "#         print(conf)\n",
    "#         print(classes)\n",
    "\n",
    "#         # get label with max accuracy\n",
    "#         idx = np.argmax(conf)\n",
    "#         label = classes[idx]\n",
    "\n",
    "#         label = \"{}: {:.2f}%\".format(label, conf[idx] * 100)\n",
    "\n",
    "#         Y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "\n",
    "#         # write label and confidence above face rectangle\n",
    "#         cv2.putText(frame, label, (startX, Y),  cv2.FONT_HERSHEY_SIMPLEX,\n",
    "#                     0.7, (0, 255, 0), 2)\n",
    "\n",
    "    # display output\n",
    "    cv2.imshow(\"gender detection\", frame)\n",
    "\n",
    "    # press \"Q\" to stop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# release resources\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
